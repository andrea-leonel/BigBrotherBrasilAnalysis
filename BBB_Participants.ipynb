{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fde5e67-53e4-455c-a904-b3ee9e3bbf24",
   "metadata": {},
   "source": [
    "## Project: An historical analysis of the Big Brother Brasil show\n",
    "(Portuguese below)\n",
    "\n",
    "This script is part of a project that gathers historical data about the Brazilian version of the Big Brother reality show and analyses how it has changed over its 25 years of existence in terms of demographics, audience participation, and other factors. This show is the most-watched programm in Brazil and the goal is to make all this data available for other analysts who wish to explore it. At the time of writing, this is the only one-stop-shop source of BBB data online.\n",
    "\n",
    "(Portuguese) Projeto: Uma análise histórica do Big Brother Brasil\n",
    "Esse script faz parte de um projeto que coleta dados históricos sobre o Big Brother Brasil de diferentes fontes e os disponibiliza de forma limpa, normalizada e com as devidas conexões. O objetivo desse projeto é tornar os dados acessíveis para outras pessoas que desejarem analisá-los e, no momento da sua publicação, essaé a única fonte de dados consolidada sobre o Big Brother Brasil.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52730adc-b882-4fc8-adf7-f59348a87c0f",
   "metadata": {},
   "source": [
    "## Script: pulling contestant information from Wikipedia\n",
    "(Portuguese below)\n",
    "\n",
    "This script gathers data about the contestants from Wikipedia and structures it in a dataframe. There are also cleaning, normalisation and optimisation steps added to it.\n",
    "\n",
    "Script: puxando dados dos participantes da Wikipedia\n",
    "Esse script puxa dados dos participantes da Wikipedia e os estruturam em um dataframe. Além disso, os dados são limpos, normalizados e otimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6334adcf-d581-4640-81d4-1813b5a7faa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display\n",
    "from io import StringIO\n",
    "import csv\n",
    "import gzip\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96bedd5-2330-4b93-b332-191b4288fa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10660\\1351883944.py:13: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n"
     ]
    }
   ],
   "source": [
    "# URL of the Wikipedia page containing 25 tables with the contestants' information\n",
    "url = \"https://pt.wikipedia.org/wiki/Lista_de_participantes_do_Big_Brother_Brasil\"\n",
    "\n",
    "# Requesting the URL and locating the relevant tables\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "tables = soup.find_all(\"table\", {\"class\": \"wikitable\"})\n",
    "\n",
    "#Storing the tables into a dataframe with a table identifier 'Edicao' (Season).\n",
    "dataframes = []\n",
    "\n",
    "for i, table in enumerate(tables):  # Skip the first two tables\n",
    "    df = pd.read_html(str(table))[0]  # Convert HTML table to DataFrame\n",
    "    df['Edicao'] = f'{i+1}'  # Add a TableID column, start from Table_3\n",
    "    dataframes.append(df)\n",
    "\n",
    "contestants = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# One of the tables had the Name column named differently, fixing this:\n",
    "contestants['Nome completo'] = contestants['Nome completo'].fillna(contestants['Participantes']) \n",
    "\n",
    "# Removing spaces and accents from column names\n",
    "contestants.rename(columns={'Nome completo': 'Nome'}, inplace=True)\n",
    "contestants.rename(columns={'Data de nascimento': 'Data_Nascimento'}, inplace=True)\n",
    "contestants.rename(columns={'Profissão': 'Profissao'}, inplace=True)\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "contestants = contestants.drop(columns=['Ref.', 'Participantes'])\n",
    "\n",
    "# Removing headers of subsequent tables\n",
    "contestants = contestants[contestants[\"Origem\"].str.contains(\"Origem\") == False]\n",
    "\n",
    "# There is an error related to the str() function but the dataframe is still created correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251afde-3e12-4c80-8e0d-b93fa2561485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking normalisation of the Origem column\n",
    "\n",
    "unique_origem = sorted(contestants['Origem'].unique().tolist())\n",
    "##for origem in unique_origem:\n",
    "    ##print(origem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "id": "f3fd1b60-693b-43d8-94bc-c70d3ee0f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for nas\n",
    "rows_with_na = contestants[contestants.isna().any(axis=1)]\n",
    "\n",
    "#display(rows_with_na)\n",
    "\n",
    "#There were nas under the Results column for the ongoing season. Replaced these with \"Ongoing\". \n",
    "\n",
    "contestants['Resultado'] = contestants['Resultado'].fillna(value=\"Em andamento em Em andamento\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "77c838f7-a64c-4081-9d71-7cff5168be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some contestants are foreigners so we need an extra column to identify if they are Brazilian.\n",
    "\n",
    "brazil_states = ['Acre','Alagoas','Amapá','Amazonas','Bahia','Ceará','Espírito Santo','Goiás','Maranhão','Mato Grosso','Mato Grosso do Sul','Minas Gerais', 'Pará','Paraíba','Paraná','Pernambuco','Piauí','Rio de Janeiro','Rio Grande do Norte','Rio Grande do Sul','Rondônia','Roraima','Santa Catarina','São Paulo','Sergipe','Tocantins','Distrito Federal']\n",
    "\n",
    "contestants['Nacionalidade'] = contestants['Origem'].apply(lambda x: 'Brasileiro' if any(sub in x for sub in brazil_states) else 'Estrangeiro')\n",
    "\n",
    "\n",
    "# Checking if the new column is correct\n",
    "rows_with_foreigners = contestants.loc[contestants['Nacionalidade'] == 'Brasileiro']\n",
    "\n",
    "##unique_origem = sorted(rows_with_foreigners['Origem'].unique().tolist())\n",
    "##for origem in unique_origem:\n",
    "    ##print(origem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "id": "2a2ee9c9-d189-47dc-a74a-e47af47b6fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Origem column into City & State for Brazilians. For foreigners, it should say \"Foreigner\".\n",
    "\n",
    "contestants[['Cidade','Estado']] = contestants['Origem'].str.split(', ', expand=True)\n",
    "\n",
    "condition = contestants['Nacionalidade'] == 'Estrangeiro'\n",
    "contestants.loc[condition,['Cidade']] = 'Estrangeiro'\n",
    "contestants.loc[condition,['Estado']] = 'Estrangeiro'\n",
    "\n",
    "#Removing the Origem column\n",
    "\n",
    "contestants = contestants.drop(columns=['Origem'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "id": "17473fa7-e10f-4319-a0ec-4e86baa93c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Resultado column to show the Result and Date separately\n",
    "\n",
    "contestants[['Resultado','Data_Resultado']] = contestants['Resultado'].str.split(' em ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "9bbadaed-3a6a-4251-8da0-9e7bd1c0278d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Data_Nascimento</th>\n",
       "      <th>Profissao</th>\n",
       "      <th>Resultado</th>\n",
       "      <th>Edicao</th>\n",
       "      <th>Nacionalidade</th>\n",
       "      <th>Cidade</th>\n",
       "      <th>Estado</th>\n",
       "      <th>Data_Resultado</th>\n",
       "      <th>Primeiro_Nome</th>\n",
       "      <th>Genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Kaysar Dadour</td>\n",
       "      <td>9 de julho de 1989</td>\n",
       "      <td>Garçom</td>\n",
       "      <td>2º lugar</td>\n",
       "      <td>18</td>\n",
       "      <td>Estrangeiro</td>\n",
       "      <td>Estrangeiro</td>\n",
       "      <td>Estrangeiro</td>\n",
       "      <td>19 de abril de 2018</td>\n",
       "      <td>KAYSAR</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Nome     Data_Nascimento Profissao Resultado Edicao  \\\n",
       "266  Kaysar Dadour  9 de julho de 1989    Garçom  2º lugar     18   \n",
       "\n",
       "    Nacionalidade       Cidade       Estado       Data_Resultado  \\\n",
       "266   Estrangeiro  Estrangeiro  Estrangeiro  19 de abril de 2018   \n",
       "\n",
       "    Primeiro_Nome Genero  \n",
       "266        KAYSAR     NA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding Gender using data from the Brazilian Census. When the names are not included in the census, it uses the gendered words in Resultado to determine Gender.\n",
    "\n",
    "#Extracting the csv file with census data and storing it in a dictionary\n",
    "def load_data():\n",
    "    fobj = io.TextIOWrapper(gzip.open(r\"C:\\Users\\andre\\Desktop\\Consultancy\\Portfolio\\Big Brother Brasil\\nomes.csv.gz\"), encoding=\"utf-8\")\n",
    "    csv_reader = csv.DictReader(fobj)\n",
    "    data = {\n",
    "        row[\"first_name\"]: row[\"classification\"]\n",
    "        for row in csv_reader\n",
    "    }\n",
    "    fobj.close()\n",
    "    return data\n",
    "\n",
    "gender_dict = load_data()\n",
    "\n",
    "# Printing a sample of the dictionary\n",
    "\n",
    "##num_lines = 10\n",
    "##for i, (key, value) in enumerate(gender_dict.items()):\n",
    "    ##if i >= num_lines:\n",
    "        ##break\n",
    "    ##print(f\"{key}: {value}\")\n",
    "\n",
    "# Function to extract first name from Name, uppercase it, and remove accents to match the dictionary formatting\n",
    "def get_first_name(Nome):\n",
    "    first_name = Nome.split()[0]\n",
    "    first_name = unidecode(first_name)\n",
    "    return first_name.upper()\n",
    "\n",
    "# Apply the function to extract first names\n",
    "contestants['Primeiro_Nome'] = contestants['Nome'].apply(get_first_name)\n",
    "\n",
    "contestants['Genero'] = contestants['Primeiro_Nome'].map(gender_dict)\n",
    "\n",
    "# For the Names not included in the census, try to identify the gender based on gendered words in Resultado.\n",
    "\n",
    "# Function to determine gender based on the last letter of the Resultado column\n",
    "def determine_gender(Resultado):\n",
    "    if Resultado[-1].lower() == 'a':\n",
    "        return 'F'\n",
    "    elif Resultado[-1].lower() == 'o':\n",
    "        return 'M'\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "# Apply the function only to rows where 'Gender' is NaN\n",
    "contestants['Genero'] = contestants.apply(\n",
    "    lambda row: determine_gender(row['Resultado']) if pd.isna(row['Genero']) else row['Genero'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "display(contestants.loc[contestants['Genero'] == 'NA']) #Showing names that were not able to be gendered\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "id": "fdd77d0c-ab5e-4ca0-9a05-6ab226b058a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising gendered words in Resultado\n",
    "\n",
    "contestants['Resultado'] = contestants['Resultado'].replace('Vencedora','Vencedor')\n",
    "contestants['Resultado'] = contestants['Resultado'].str.replace(r'\\beliminada\\b', 'eliminado', regex=True)\n",
    "contestants['Resultado'] = contestants['Resultado'].replace('Expulsa','Expulso')\n",
    "contestants['Resultado'] = contestants['Resultado'].replace('Retirada','Retirado')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "id": "afa00e57-d1d1-43b8-ad69-4ba832c614c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if new columns are correct\n",
    "##unique_resultado = sorted(contestants['Resultado'].unique().tolist())\n",
    "##for resultado in unique_resultado:\n",
    "    ##print(resultado)\n",
    "\n",
    "##unique_data = sorted(contestants['Data_Resultado'].unique().tolist())\n",
    "##for data in unique_data:\n",
    "    ##print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "id": "44fa62a1-2001-40a9-8e94-105cd02e11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the year of each contestant show\n",
    "\n",
    "contestants['Ano_Edicao'] = contestants['Data_Resultado'].str.slice(-4)\n",
    "contestants.loc[contestants['Data_Resultado'] == 'Em andamento', \"Ano_Edicao\"] = \"2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "0bdb40b9-214e-4cb4-80b2-47b5b210722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique ids for the contestants\n",
    "\n",
    "unique_contestants = contestants['Nome'].unique()\n",
    "name_to_id = {name: id for id, name in enumerate(unique_contestants, start=1)}\n",
    "\n",
    "contestants['ID_Participante'] = contestants['Nome'].map(name_to_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "ebbd8bce-4a8a-43e7-86f8-3fd075f08e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Normalising gendered words in Profissao\n",
    "\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('endedora', 'endedor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ssessora', 'ssessor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('dvogada', 'dvogado', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Atriz', 'Ator', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('atriz', 'ator', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('arwoman', 'arman', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('iomédica', 'iomédico', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ióloga', 'iólogo', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('abeleireira', 'abeleireiro', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('antora', 'antor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('irurgiã ', 'irurgião ', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('irurgiã-', 'irurgião-', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Aeromoça', 'Comissário de voo', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('onsultora', 'onsultor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ançarina', 'ançarino', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Dona', 'Dono', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('mpresária', 'mpresário', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('nfermeira', 'nfermeiro', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ngenheira', 'ngenheiro', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Criadora de conteúdo', 'Influenciador digital', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ogadora', 'ogador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('utadora', 'utador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('aquiadora', 'aquiador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('presentadora', 'presentador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('otogirl', 'otoboy', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('édica', 'édico', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('rodutora', 'rodutor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('rofessora', 'rofessor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('outora ', 'outor ', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('romotora', 'romotor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('écnica', 'écnico', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('sicóloga', 'sicólogo', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ublicitária', 'ublicitário', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('radutora', 'radutor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('peradora', 'perador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('nfermeira', 'nfermeiro', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('youtuber', 'influenciador digital', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Youtuber', 'Influenciador digital', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('nfluenciadora digital', 'nfluenciador digital', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('posentada', 'posentado', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ducadora', 'ducador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Ginasta', 'Atleta de ginástica artística', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ailarina', 'ailarino', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('onciliadora', 'onciliador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('onfeiteira', 'onfeiteiro', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('oordenadora', 'oordenador', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('orretora', 'orretor', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Hostess', 'Host', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('ráfica', 'ráfico', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Doceira', 'Confeiteiro', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('musa', 'muso', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('grônoma', 'grônomo', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('uncionária pública', 'uncionário público', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('arota', 'aroto', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('otoqueiro', 'otoboy', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Paratleta', 'Atleta paratleta', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Surfista profissional', 'Surfista', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('Surfista', 'Atleta surfista', regex=True)\n",
    "contestants['Profissao'] = contestants['Profissao'].str.replace('eterinária', 'eterinário', regex=True)\n",
    "\n",
    "#Checking professions\n",
    "##unique_profissao = sorted(contestants['Profissao'].unique().tolist())\n",
    "##for profissao in unique_profissao:\n",
    "    ##print(profissao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "id": "418e9754-6807-42b8-b095-1db9ea576db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save the dataframe to CSV to my local drive\n",
    "\n",
    "contestants.to_csv(r'C:\\Users\\andre\\Desktop\\Consultancy\\Portfolio\\Big Brother Brasil\\contestants.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
